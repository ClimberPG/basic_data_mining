{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, num_rounds=1000):\n",
    "    param = {}\n",
    "    param['booster'] = 'gblinear'\n",
    "    param['objective'] = 'reg:linear'\n",
    "    param['silent'] = 1\n",
    "    # param['eta'] = 0.1\n",
    "    # param['max_depth'] = 10  \n",
    "    # param['min_child_weight'] = 1\n",
    "    # param['subsample'] = 0.9\n",
    "    num_rounds = num_rounds\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest)\n",
    "    return pred_test_y, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 386)\n",
      "(25000, 385)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"\"\n",
    "train_file = data_path + \"save_train.csv\"\n",
    "test_file = data_path + \"save_test.csv\"\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train_df[\"reference\"]\n",
    "train_X = train_df.iloc[0:,:-1]\n",
    "test_X = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:13.1592\ttest-rmse:13.2107\n",
      "Multiple eval metrics have been passed: 'test-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until test-rmse hasn't improved in 20 rounds.\n",
      "[1]\ttrain-rmse:11.3183\ttest-rmse:11.3391\n",
      "[2]\ttrain-rmse:10.1385\ttest-rmse:10.1168\n",
      "[3]\ttrain-rmse:9.8963\ttest-rmse:9.89742\n",
      "[4]\ttrain-rmse:9.48241\ttest-rmse:9.54467\n",
      "[5]\ttrain-rmse:9.17702\ttest-rmse:9.26847\n",
      "[6]\ttrain-rmse:8.98461\ttest-rmse:9.09265\n",
      "[7]\ttrain-rmse:8.79298\ttest-rmse:8.91174\n",
      "[8]\ttrain-rmse:8.68097\ttest-rmse:8.81257\n",
      "[9]\ttrain-rmse:8.61839\ttest-rmse:8.75486\n",
      "[10]\ttrain-rmse:8.55185\ttest-rmse:8.68713\n",
      "[11]\ttrain-rmse:8.51108\ttest-rmse:8.65615\n",
      "[12]\ttrain-rmse:8.48358\ttest-rmse:8.64092\n",
      "[13]\ttrain-rmse:8.45424\ttest-rmse:8.59561\n",
      "[14]\ttrain-rmse:8.41976\ttest-rmse:8.55093\n",
      "[15]\ttrain-rmse:8.39339\ttest-rmse:8.5184\n",
      "[16]\ttrain-rmse:8.3651\ttest-rmse:8.4847\n",
      "[17]\ttrain-rmse:8.3422\ttest-rmse:8.45385\n",
      "[18]\ttrain-rmse:8.32317\ttest-rmse:8.43157\n",
      "[19]\ttrain-rmse:8.31191\ttest-rmse:8.41293\n",
      "[20]\ttrain-rmse:8.29945\ttest-rmse:8.4003\n",
      "[21]\ttrain-rmse:8.2905\ttest-rmse:8.38954\n",
      "[22]\ttrain-rmse:8.28366\ttest-rmse:8.38064\n",
      "[23]\ttrain-rmse:8.27345\ttest-rmse:8.36995\n",
      "[24]\ttrain-rmse:8.28003\ttest-rmse:8.37523\n",
      "[25]\ttrain-rmse:8.27385\ttest-rmse:8.36006\n",
      "[26]\ttrain-rmse:8.26146\ttest-rmse:8.34444\n",
      "[27]\ttrain-rmse:8.25305\ttest-rmse:8.33412\n",
      "[28]\ttrain-rmse:8.24881\ttest-rmse:8.32889\n",
      "[29]\ttrain-rmse:8.24526\ttest-rmse:8.32556\n",
      "[30]\ttrain-rmse:8.24395\ttest-rmse:8.32471\n",
      "[31]\ttrain-rmse:8.2862\ttest-rmse:8.35503\n",
      "[32]\ttrain-rmse:8.25766\ttest-rmse:8.33662\n",
      "[33]\ttrain-rmse:8.24831\ttest-rmse:8.32949\n",
      "[34]\ttrain-rmse:8.24032\ttest-rmse:8.31631\n",
      "[35]\ttrain-rmse:8.235\ttest-rmse:8.3078\n",
      "[36]\ttrain-rmse:8.2317\ttest-rmse:8.3084\n",
      "[37]\ttrain-rmse:8.22771\ttest-rmse:8.30353\n",
      "[38]\ttrain-rmse:8.22427\ttest-rmse:8.29909\n",
      "[39]\ttrain-rmse:8.22161\ttest-rmse:8.29498\n",
      "[40]\ttrain-rmse:8.21952\ttest-rmse:8.29552\n",
      "[41]\ttrain-rmse:8.21771\ttest-rmse:8.29401\n",
      "[42]\ttrain-rmse:8.21609\ttest-rmse:8.29348\n",
      "[43]\ttrain-rmse:8.21678\ttest-rmse:8.29972\n",
      "[44]\ttrain-rmse:8.21462\ttest-rmse:8.29499\n",
      "[45]\ttrain-rmse:8.21203\ttest-rmse:8.2906\n",
      "[46]\ttrain-rmse:8.2104\ttest-rmse:8.29058\n",
      "[47]\ttrain-rmse:8.2089\ttest-rmse:8.29014\n",
      "[48]\ttrain-rmse:8.20775\ttest-rmse:8.28737\n",
      "[49]\ttrain-rmse:8.20629\ttest-rmse:8.28758\n",
      "[50]\ttrain-rmse:8.20496\ttest-rmse:8.28616\n",
      "[51]\ttrain-rmse:8.20388\ttest-rmse:8.2863\n",
      "[52]\ttrain-rmse:8.20274\ttest-rmse:8.28489\n",
      "[53]\ttrain-rmse:8.20174\ttest-rmse:8.28628\n",
      "[54]\ttrain-rmse:8.20093\ttest-rmse:8.28359\n",
      "[55]\ttrain-rmse:8.20021\ttest-rmse:8.2856\n",
      "[56]\ttrain-rmse:8.19955\ttest-rmse:8.28547\n",
      "[57]\ttrain-rmse:8.19883\ttest-rmse:8.28409\n",
      "[58]\ttrain-rmse:8.19821\ttest-rmse:8.2825\n",
      "[59]\ttrain-rmse:8.19781\ttest-rmse:8.28237\n",
      "[60]\ttrain-rmse:8.19707\ttest-rmse:8.28138\n",
      "[61]\ttrain-rmse:8.19653\ttest-rmse:8.28152\n",
      "[62]\ttrain-rmse:8.19794\ttest-rmse:8.27791\n",
      "[63]\ttrain-rmse:8.19639\ttest-rmse:8.28003\n",
      "[64]\ttrain-rmse:8.19547\ttest-rmse:8.2804\n",
      "[65]\ttrain-rmse:8.19473\ttest-rmse:8.27937\n",
      "[66]\ttrain-rmse:8.19418\ttest-rmse:8.28031\n",
      "[67]\ttrain-rmse:8.19353\ttest-rmse:8.27941\n",
      "[68]\ttrain-rmse:8.19297\ttest-rmse:8.27802\n",
      "[69]\ttrain-rmse:8.1928\ttest-rmse:8.27842\n",
      "[70]\ttrain-rmse:8.19211\ttest-rmse:8.27877\n",
      "[71]\ttrain-rmse:8.19159\ttest-rmse:8.279\n",
      "[72]\ttrain-rmse:8.19112\ttest-rmse:8.27836\n",
      "[73]\ttrain-rmse:8.19065\ttest-rmse:8.27696\n",
      "[74]\ttrain-rmse:8.19027\ttest-rmse:8.27742\n",
      "[75]\ttrain-rmse:8.1899\ttest-rmse:8.27661\n",
      "[76]\ttrain-rmse:8.1896\ttest-rmse:8.27668\n",
      "[77]\ttrain-rmse:8.18923\ttest-rmse:8.27603\n",
      "[78]\ttrain-rmse:8.18884\ttest-rmse:8.27598\n",
      "[79]\ttrain-rmse:8.18853\ttest-rmse:8.27536\n",
      "[80]\ttrain-rmse:8.18844\ttest-rmse:8.27652\n",
      "[81]\ttrain-rmse:8.21469\ttest-rmse:8.29396\n",
      "[82]\ttrain-rmse:8.19794\ttest-rmse:8.27453\n",
      "[83]\ttrain-rmse:8.19394\ttest-rmse:8.27295\n",
      "[84]\ttrain-rmse:8.19126\ttest-rmse:8.27476\n",
      "[85]\ttrain-rmse:8.19169\ttest-rmse:8.27416\n",
      "[86]\ttrain-rmse:8.1894\ttest-rmse:8.27691\n",
      "[87]\ttrain-rmse:8.18834\ttest-rmse:8.2763\n",
      "[88]\ttrain-rmse:8.18774\ttest-rmse:8.27864\n",
      "[89]\ttrain-rmse:8.1899\ttest-rmse:8.28179\n",
      "[90]\ttrain-rmse:8.18881\ttest-rmse:8.28189\n",
      "[91]\ttrain-rmse:8.18749\ttest-rmse:8.27989\n",
      "[92]\ttrain-rmse:8.18732\ttest-rmse:8.28214\n",
      "[93]\ttrain-rmse:8.18639\ttest-rmse:8.27951\n",
      "[94]\ttrain-rmse:8.18587\ttest-rmse:8.2781\n",
      "[95]\ttrain-rmse:8.18568\ttest-rmse:8.27826\n",
      "[96]\ttrain-rmse:8.18522\ttest-rmse:8.2782\n",
      "[97]\ttrain-rmse:8.18539\ttest-rmse:8.27732\n",
      "[98]\ttrain-rmse:8.18488\ttest-rmse:8.27623\n",
      "[99]\ttrain-rmse:8.18453\ttest-rmse:8.27531\n",
      "[100]\ttrain-rmse:8.18431\ttest-rmse:8.27499\n",
      "[101]\ttrain-rmse:8.18404\ttest-rmse:8.27364\n",
      "[102]\ttrain-rmse:8.1839\ttest-rmse:8.27357\n",
      "[103]\ttrain-rmse:8.18358\ttest-rmse:8.27336\n",
      "Stopping. Best iteration:\n",
      "[83]\ttrain-rmse:8.19394\ttest-rmse:8.27295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.KFold(n_splits=5)\n",
    "for dev_index, val_index in kf.split(range(train_X.shape[0])):\n",
    "        dev_X, val_X = train_X.iloc[dev_index,:], train_X.iloc[val_index,:]\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "        preds, model = runXGB(dev_X, dev_y, val_X, val_y, num_rounds=3000)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds, model = runXGB(train_X, train_y, test_X, num_rounds=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"reference\"]\n",
    "out_df.insert(0, \"id\", test_df[\"id\"])\n",
    "out_df.to_csv(\"xgboost_pro1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
